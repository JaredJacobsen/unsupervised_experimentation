{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import math\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - x.mean())/x.std()\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnist.loader.MNIST"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('./data/mnist/')\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_layers_from_params(params):\n",
    "    return int(len(params)/2)\n",
    "\n",
    "def initialize(num_nodes_per_layer, input_size):    \n",
    "    params = {}\n",
    "    \n",
    "    prev_input_size = input_size\n",
    "    for l, n in enumerate(num_nodes_per_layer):\n",
    "        bound = np.sqrt(2/prev_input_size)\n",
    "        params['W' + str(l + 1)] = np.random.uniform(-bound, bound, (n, prev_input_size))\n",
    "        params['b' + str(l + 1)] = np.zeros((n, 1))\n",
    "        prev_input_size = n\n",
    "        \n",
    "    return params\n",
    "\n",
    "def predict(x, params):\n",
    "    a = x.reshape((x.shape[0],1))\n",
    "    for l in range(1, get_num_layers_from_params(params) + 1):\n",
    "        W = params['W' + str(l)]\n",
    "        b = params['b' + str(l)]\n",
    "        z = W.dot(a) + b\n",
    "#         print(z)\n",
    "        a = sigmoid(z)\n",
    "#     print(a.shape)\n",
    "    return a.reshape((a.shape[0],))\n",
    "\n",
    "def update_weights(a_prev, a, W, b, learning_rate):\n",
    "    gradient = a*(1 - a)*a_prev.T\n",
    "    sm_a = softmax(a)\n",
    "    delta_W = sm_a*W*(gradient)*learning_rate\n",
    "    delta_W = delta_W/(np.square(W) + 10)\n",
    "    W = W + delta_W\n",
    "    W = np.apply_along_axis(lambda x: x/x.sum(), 1, W)\n",
    "#     delta_b = sm_a*(a*(1 - a))*learning_rate\n",
    "#     b = b + delta_b\n",
    "    return W, b\n",
    "\n",
    "def unsupervised_train(X, params, learning_rate=0.1):\n",
    "    params = params.copy()\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i, :].T\n",
    "        a_prev = x.reshape((x.shape[0],1))\n",
    "        for l in range(1, get_num_layers_from_params(params) + 1):\n",
    "            W = params['W' + str(l)]\n",
    "            b = params['b' + str(l)]\n",
    "            z = W.dot(a_prev) + b\n",
    "#             if i % 100 == 0:\n",
    "#                 print(W.sum().sum())\n",
    "#                 print(z)\n",
    "            a = sigmoid(z)\n",
    "            params['W' + str(l)], params['b' + str(l)] = update_weights(a_prev, a, W, b, learning_rate)\n",
    "            a_prev = a\n",
    "    return params\n",
    "\n",
    "def transform_X(X, params):\n",
    "    return np.apply_along_axis(lambda x: predict(x, params), 1, X)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jared/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained:  0.4282      untrained:  0.0633\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "X = train_images[0:n, :]\n",
    "y = train_labels[0:n]\n",
    "\n",
    "X = np.apply_along_axis(normalize, 1, X)\n",
    "params = initialize([20, 15], 784)\n",
    "trained_params = unsupervised_train(X, params)\n",
    "transformed_X = transform_X(X, trained_params)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(transformed_X, y)\n",
    "\n",
    "test_X = np.apply_along_axis(normalize, 1, test_images)\n",
    "trained_params_score = lr.score(transform_X(test_X, trained_params), test_labels)\n",
    "untrained_params_score = lr.score(transform_X(test_X, params), test_labels)\n",
    "\n",
    "print('trained: ', trained_params_score, '     untrained: ', untrained_params_score)\n",
    "\n",
    "# lr.fit(X, y).score(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_X(test_X, trained_params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 (20, 784)\n",
      "b1 (20, 1)\n",
      "W2 (10, 20)\n",
      "b2 (10, 1)\n",
      "W3 (10, 10)\n",
      "b3 (10, 1)\n"
     ]
    }
   ],
   "source": [
    "for k, v in trained_params.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
